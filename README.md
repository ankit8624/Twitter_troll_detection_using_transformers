
# ğŸ¦ Twitter Troll Detection using DeBERTa  
*A deep learning-based system to classify tweets as troll or not.*

## ğŸš€ Live Demo  
ğŸ”— **Try the app here:** [Your Deployment Link](https://twitter-troll-detection.streamlit.app/)  

## ğŸ“Œ Project Overview  
- This project uses **DeBERTa** (Deep Bidirectional Encoder Representations from Transformers) to classify tweets into three categories.  
- It includes a **Streamlit web app** for easy user interaction.  

## ğŸ› ï¸ Features  
âœ… Multi-class troll detection (3 categories)  
âœ… Built using **Deep Learning** and **NLP**  
âœ… Interactive **Streamlit web app**  
âœ… Pre-trained **DeBERTa model**  


## ğŸ“¦ Installation  
### 1ï¸âƒ£ Clone the repository  
```bash
git clone https://github.com/ankit8624/Twitter_troll_detection_using_transformers.git
cd Twitter_troll_detection_using_transformers
```
### 2ï¸âƒ£ Install dependencies  
```bash
pip install -r requirements.txt
``` 
### 3ï¸âƒ£ Run the Streamlit app  
```bash
streamlit run app.py
```

## ğŸ“Š Model Performance  
### ğŸ“œ Classification Report  
| Class | Precision | Recall | F1-Score | Support |
|-------|----------|--------|----------|---------|
| **0** | 0.95     | 0.88   | 0.91     | 3000    |
| **1** | 0.74     | 0.90   | 0.81     | 1000    |
| **2** | 0.79     | 0.80   | 0.79     | 1000    |
| **Accuracy** | **-** | **-** | **0.86** | **5000** |
| **Macro Avg** | 0.82 | 0.86 | 0.84 | 5000 |
| **Weighted Avg** | 0.87 | 0.86 | 0.87 | 5000 |

### ğŸ” Confusion Matrix  
![Confusion Matrix](image.png)  

## ğŸ—‚ Dataset  
- **Source**: [Twitter and Reddit Sentimental Analysis Dataset](https://www.kaggle.com/datasets/cosmos98/twitter-and-reddit-sentimental-analysis-dataset)  
- **Description**: This dataset contains tweets and Reddit posts labeled for sentiment analysis.  
- **Usage**: Used for training and testing a troll detection model.  

## ğŸ”„ Data Preprocessing  
- **Text Cleaning**: Removed special characters, links, hashtags, and mentions.  
- **Lowercasing**: Converted text to lowercase for uniformity.  
- **Stopword Removal**: Removed common words (e.g., "the", "is") using NLTK.  
- **Tokenization**: Split text into individual words using SpaCy.  
- **Lemmatization**: Converted words to their root form.  
- **Padding & Truncation**: Standardized tweet lengths for model input.  

## ğŸ§  Model Details  
- **Model**: DeBERTa (Deep Bidirectional Encoder Representations from Transformers)  
- **Training**: Fine-tuned on labeled dataset  
- **Performance**: **86% accuracy**  

## ğŸ¤ Contribution  
Want to improve this project? Feel free to fork and submit a pull request!  

## ğŸ“¬ Contact  
For any queries, reach out to me at:  
ğŸ“§ **ankit.desale@example.com**  
ğŸ“Œ [GitHub Profile](https://github.com/your-username)  
